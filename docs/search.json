[{"path":"/articles/advanced_pdp.html","id":"advanced-pdp-features","dir":"Articles","previous_headings":"","what":"Advanced PDP Features","title":"Advanced PDP Features","text":"addition standard PDP plotting prediction functions, offer several additional features. One example create PDP plots 2 features concurrently.","code":"# Load the required packages library(Distillery) library(Rforestry)  # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a random forest on the data set forest <- forestry(x=data[,-1],                    y=data[,1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")  forest_interpret <- Interpreter$new(predictor = forest_predictor)"},{"path":"/articles/advanced_pdp.html","id":"bivariate-pdp-plots","dir":"Articles","previous_headings":"","what":"Bivariate PDP Plots","title":"Advanced PDP Features","text":"order create PDP plots using plot() method, must pass arguments features.2d argument plot() function. features continuous, PDP plot become heatmap.  can also create 2d PDP plots combinations continuous categorical features.","code":"# Make 2d PDP plots pdp_plots <-  plot(forest_interpret, method = \"pdp\", features.2d = data.frame(col1 = c(\"Petal.Length\"),                                                                               col2 = c(\"Petal.Width\"))) ## Warning in xtfrm.data.frame(x): cannot xtfrm data frames  ## Warning in xtfrm.data.frame(x): cannot xtfrm data frames  ## Warning in xtfrm.data.frame(x): cannot xtfrm data frames plot(pdp_plots$Petal.Length.Petal.Width) # Make 2d PDP plots with continuous + categorical pdp_plots <-  plot(forest_interpret, method = \"pdp\", features.2d = data.frame(col1 = c(\"Petal.Length\"),                                                                               col2 = c(\"Species\"))) ## Warning in xtfrm.data.frame(x): cannot xtfrm data frames  ## Warning in xtfrm.data.frame(x): cannot xtfrm data frames  ## Warning in xtfrm.data.frame(x): cannot xtfrm data frames plot(pdp_plots$Petal.Length.Species)"},{"path":"/articles/advanced_pdp.html","id":"getting-bivariate-pdp-functions","dir":"Articles","previous_headings":"","what":"Getting Bivariate PDP Functions","title":"Advanced PDP Features","text":"can also get bivariate PDP functions Interpreter object. display predictions PDP function Species Petal.Width.","code":"preds_2d <- forest_interpret$pdp.2d$Species$Petal.Width(data.frame(col1 = iris$Species, col2 = iris$Petal.Width))  data.frame(Petal.Width = iris$Petal.Width,            Predictions = preds_2d) %>%    ggplot(aes(x = Petal.Width, y = Predictions))+   geom_point()+   theme_classic()"},{"path":"/articles/advanced_plotting.html","id":"plotting-methods","dir":"Articles","previous_headings":"","what":"Plotting Methods","title":"Plotting Methods","text":"article, provide detail different plots interpretability methods, including set number points plotted given feature, setting center plots, additional options discussed general overview.","code":""},{"path":"/articles/advanced_plotting.html","id":"interpreter-class-initialization","dir":"Articles","previous_headings":"Plotting Methods","what":"Interpreter Class Initialization","title":"Plotting Methods","text":"examples additional articles, use well-known iris dataset, provides information 50 flowers 3 species iris, random forest model predicting \"Sepal.Length\" variable. begin making interpretability plots, must start Interpreter object, consists following parameters: following parameters Interpreter object determine different aspects interpretability plots: grid.size: provides number grid points want continuous features PDP, ICE, ALE methods. larger input grid.size creates points plotted, increases fidelity plot computation time. specified Interpreter object declared. grid.points: stores lists grid points feature data. continuous features, grid points equally spaced values minimum value maximum value feature, length specified grid.size. parameter determines points plot PDP ICE methods. center.: stores list values center continuous features plotted PDP ICE curves. center defined value feature want center , rather particular value PDP ICE curve. default, set minimum value grid.points list continuous feature. , demonstrate examples parameters feature Sepal.Width:  initializing Interpreter, can still change centers grid points plot. example, provide code provide new set grid points center mean value Sepal.Width. Note set new center value, must within range grid points.  contrast fixed grid points PDP ICE methods, ALE method sets grid points based quantiles marginal distribution. , avoids sparsity within one neighborhood. ALE also always mean-centered. result, methods set.grid.points set.center.affect ALE plots. key parameter ALE method grid.size, determines number points calculated ALE.","code":"library(MASS) library(distillML) library(Rforestry) ## Warning: package 'Rforestry' was built under R version 4.1.2 ## ##  ## ##  Rforestry (Version 0.9.0.95, Build Date: R 4.1.2; x86_64-apple-darwin17.0; 2022-03-10 13:19:39 UTC; unix) ## ##  See https://github.com/forestry-labs for additional documentation. ## ##  Please cite software as: ## ##    Soren R. Kunzel, Theo F. Saarinen, Edward W. Liu, Jasjeet S. Sekhon. 2019. ## ##    ''Linear Aggregation in Tree-based Estimators.'' arXiv preprint  ## ##    arXiv:1906.06463. https://arxiv.org/abs/1906.06463  ## ## # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a random forest on the data set forest <- forestry(x=data[,-1],                    y=data[,1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")  # We specify grid.size for clarity (grid.size = 50 by default) forest_interpreter <- Interpreter$new(forest_predictor,                                       grid.size = 50) print(forest_interpreter) ## <Interpreter> ##   Public: ##     ale.grid: list ##     center.at: list ##     clone: function (deep = FALSE)  ##     data.points: 67 92 60 69 104 12 24 106 112 18 2 141 64 78 83 10 6 85  ... ##     feat.class: numeric numeric numeric factor ##     features: Sepal.Width Petal.Length Petal.Width Species ##     features.2d: data.frame ##     grid.points: list ##     grid.size: 50 ##     initialize: function (predictor = NULL, samples = 1000, data.points = NULL,  ##     pdp.1d: list ##     pdp.2d: list ##     predictor: Predictor, R6 ##     saved: list # The values of Sepal.Width to be plotted by PDP and ICE curves print(forest_interpreter$grid.points$Sepal.Width) ##  [1] 2.000000 2.048980 2.097959 2.146939 2.195918 2.244898 2.293878 2.342857 ##  [9] 2.391837 2.440816 2.489796 2.538776 2.587755 2.636735 2.685714 2.734694 ## [17] 2.783673 2.832653 2.881633 2.930612 2.979592 3.028571 3.077551 3.126531 ## [25] 3.175510 3.224490 3.273469 3.322449 3.371429 3.420408 3.469388 3.518367 ## [33] 3.567347 3.616327 3.665306 3.714286 3.763265 3.812245 3.861224 3.910204 ## [41] 3.959184 4.008163 4.057143 4.106122 4.155102 4.204082 4.253061 4.302041 ## [49] 4.351020 4.400000 # The number of grid.points is equal to the grid.size print(length(forest_interpreter$grid.points$Sepal.Width)) ## [1] 50 print(forest_interpreter$grid.size) ## [1] 50 # The value of Sepal.Width we center the PDP and ICE curves print(forest_interpreter$center.at$Sepal.Width) ## [1] 2 # plot the PDP and ICE curves plot(forest_interpreter, features = \"Sepal.Width\") ## $Sepal.Width # Set new grid points set.grid.points(forest_interpreter, \"Sepal.Width\",                  values = seq(2, 4.5, length.out = 100))  # Set new center set.center.at(forest_interpreter, \"Sepal.Width\",                mean(seq(2, 4.5, length.out = 100)))  # New plot plot(forest_interpreter, features = \"Sepal.Width\") ## $Sepal.Width # ALE plot plot(forest_interpreter, features = \"Sepal.Width\", method = \"ale\") ## $Sepal.Width"},{"path":"/articles/advanced_plotting.html","id":"advanced-feature-clustering","dir":"Articles","previous_headings":"Plotting Methods","what":"Advanced Feature: Clustering","title":"Plotting Methods","text":"package also provides new feature cluster ICE curves. default option plot Interpreter class plots ICE curves mean, PDP curve. introduce use kmeans unsupervised learning algorithm way better visualize groups ICE curves. , set method = \"ice\" plot function, can set number clusters type clustering clusters clusterType arguments respectively.   two options clusterType differ follows: * preds: predicted value ICE curve treated entry vector, ICE curves grouped based prediccted values. * gradient: Rather clustering based predicted values, gradient method takes change predicted values across consecutive grid points, clusters based changes.","code":"# Clustering Based on the Predicted Values of the ICE Curves plot(forest_interpreter,      features = \"Sepal.Width\",      method = \"ice\",      clusters = 4,      clusterType = \"preds\") ## $Sepal.Width # Clustering Based on the Change in Predicted Values of the ICE Curves plot(forest_interpreter,      features = \"Sepal.Width\",      method = \"ice\",      clusters = 4,      clusterType = \"gradient\") ## $Sepal.Width"},{"path":"/articles/ale_plots.html","id":"ale-plots","dir":"Articles","previous_headings":"","what":"ALE Plots","title":"ALE Plots","text":"interpreter object created wrap algorithm, can also create ALE plots. Given Interpreter object, can create ALE plots using plot() method setting method=\"ale\".  X axis plot displays histogram training data user can see PDP support training data.","code":"# Load the required packages library(Distillery) library(Rforestry)  # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a random forest on the data set forest <- forestry(x=data[,-1],                    y=data[,1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")  # Initialize an interpreter forest_interpret <- Interpreter$new(predictor = forest_predictor) ale_plots <-  plot(forest_interpret, method = \"ale\", features = \"Sepal.Width\") plot(ale_plots$Sepal.Width)"},{"path":"/articles/cluster_ice.html","id":"clustering-ice-plots","dir":"Articles","previous_headings":"","what":"Clustering ICE Plots","title":"ICE Clustering","text":"Often PDP plots tell whole story model fit. individual conditional expectation plots can let us examine predictions model granular level. note PDP plots average training data ICE plots. Given Interpreter object, can create ICE plots using plot() method setting method=\"ice\". one also wants include PDP plot, one can use method=\"pdp+ice\".","code":"# Load the required packages library(Distillery) library(Rforestry)  # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a random forest on the data set forest <- forestry(x=data[,-1],                    y=data[,1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")  # Initialize an interpreter forest_interpret <- Interpreter$new(predictor = forest_predictor) ice_plots <-  plot(forest_interpret, method = \"ice\", features = \"Sepal.Width\") plot(ice_plots$Sepal.Width)"},{"path":"/articles/cluster_ice.html","id":"clustering-the-ice-plots","dir":"Articles","previous_headings":"","what":"Clustering the ICE Plots","title":"ICE Clustering","text":"ICE plots can show heterogeneity model predictions, offer option cluster ICE lines using unsupervised learning. order create clusters, one must set desired number clusters clusters argument.","code":"ice_plots <-  plot(forest_interpret, method = \"ice\", features = \"Sepal.Width\", clusters = 4) plot(ice_plots$Sepal.Width)"},{"path":"/articles/cluster_ice.html","id":"clustering-based-on-gradients","dir":"Articles","previous_headings":"","what":"Clustering Based on Gradients","title":"ICE Clustering","text":"can cluster ICE lines based either values, setting clusterType = \"preds\" gradient, setting clusterType = \"gradient\".","code":"ice_plots <-  plot(forest_interpret, method = \"ice\", features = \"Sepal.Width\", clusters = 4, clusterType = \"gradient\") plot(ice_plots$Sepal.Width)"},{"path":"/articles/local_surrogates.html","id":"local-surrogate-models-for-bivariate-pdp-functions","dir":"Articles","previous_headings":"","what":"Local Surrogate Models for Bivariate PDP Functions","title":"Local Surrogate","text":"cases, can difficult understand output bivariate PDP function. alternative visualizing functions, can fit small decision tree using PDP function values outcomes two features (possibly interaction) independent features. localSurrogate function package provides comprehensive method interpreting bivariate PDP results plotting output bivariate predictions returning weak-learner decision tree. article, demonstrate use localSurrogate function, specify different parameters weak learner returned. method implemented localSurrogate() function. two arguments required Interpreter object, two-column dataframe row pair feature names. returned object consists two distinct lists: plots: list contains bivariate PDP plots. pair two continous features, returns heatmap. pair one continuous one categorical feature, returns conditional PDP plot, curves grouped based continuous feature value. models: list contains weak learners, can make predictions plotted visualization.   can also include interation term pair features specifying argument interact TRUE. default, argument FALSE. change parameters weak-learner, can specify list parameters argument params.forestry. default, weak learner uses one tree, maximum depth 2. , demonstrate one might use arguments including interactions letting tree grow maximum depth 3. details, please refer documentation localSurrogate provided “References” section.","code":"# Load the required packages library(distillML) library(Rforestry)  # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a random forest on the data set forest <- forestry(x=data[,-1],                    y=data[,1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")  # Create the interpreter object forest_interpret <- Interpreter$new(predictor = forest_predictor) # Make the bivariate PDP function local.surr <- localSurrogate(forest_interpret,                              features.2d = data.frame(col1 = c(\"Sepal.Width\",                                                                \"Sepal.Width\"),                                                       col2 = c(\"Species\",                                                                \"Petal.Width\")))  # examples of the plot plot(local.surr$plots$Sepal.Width.Species) plot(local.surr$plots$Sepal.Width.Petal.Width) # examples of the weak learner plot(local.surr$models$Sepal.Width.Species) plot(local.surr$models$Sepal.Width.Petal.Width) # Include interactions and let the maximum depth be 3 local.surr <- localSurrogate(forest_interpret,                              features.2d = data.frame(col1 = c(\"Sepal.Width\"),                                                       col2 = c(\"Petal.Width\")),                              interact = T,                              params.forestry = list(ntree = 1, maxDepth = 3))  # Plot the resulting local surrogate model plot(local.surr$models$Sepal.Width.Petal.Width)"},{"path":"/articles/model_distillation.html","id":"model-distillation","dir":"Articles","previous_headings":"","what":"Model Distillation","title":"Distillation Methods","text":"can distill general machine learning model interpretable additive combination PDP functions model. done creating linear combination univariate PDP curves nonnegative weights, fit predictions original model. create surrogate model original model, first create Interpreter object. create surrogate model Interpreter object, call function distill, set important arguments determining surrogate model makes predictions. underlying method fitting weights package glmnnet, enables us enforce sparsity lasso ridge regression cross-validation. , give brief explanations key arguments distill method. features: argument vector feature indices. index feature index feature’s name Interpreter object’s vector features, can accessed example forest_interpret$features$. default value features include indices valid features. cv: argument takes boolean value determines whether want cross-validate weights derive PDP curve. argument default FALSE, set TRUE want induce sparsity lasso ridge regression. snap.grid: argument takes boolean value determines surrogate model make predictions using approximations previously calculated values. default, TRUE. computationally expensive calculations involved PDP curves, switched FALSE small training datasets small user-specified samples argument declaring Interpreter object. snap.train: argument takes boolean value determines make approximations marginal distribution subsampled training data, equally spaced grid points. default, TRUE, means surrogate model uses marginal distirbution subsampled training data. switched FALSE, distillation process becomes computationally expensive due predict equally-spaced grid points. distill method returns Surrogate object, can used predictions. see coefficients, value categorical variable one-hot encoded weight-fitting process. case, get three different coefficients Species feature, one three species iris.","code":"# Load the required packages library(distillML) library(Rforestry)  # Load in data  data(\"iris\") set.seed(491) data <- iris  # Split data into train and test sets train <- data[1:100, ] test <- data[101:150, ]  # Train a random forest on the data set forest <- forestry(x=train[, -1],                    y=train[, 1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")  forest_interpret <- Interpreter$new(predictor = forest_predictor) # Distilling the Model With Default Settings distilled_model <- distill(forest_interpret) print(distilled_model) ## <Surrogate> ##   Public: ##     center.mean: TRUE ##     clone: function (deep = FALSE)  ##     feature.centers: 5.68409008109431 5.69014503495339 5.70669254287596 5.684 ... ##     features: 1 2 3 4 ##     grid: list ##     initialize: function (interpreter, features, weights, intercept, feature.centers,  ##     intercept: 5.70095795529679 ##     interpreter: Interpreter, R6 ##     snap.grid: TRUE ##     weights: 1.48181923180554 1.305763819228 0.778386391268475 0.9033 ... # get weights for each PDP curve print(distilled_model$weights) ##        Sepal.Width       Petal.Length        Petal.Width Species_versicolor  ##          1.4818192          1.3057638          0.7783864          0.9033819  ##  Species_virginica     Species_setosa  ##          0.7656621          0.8530705"},{"path":"/articles/model_distillation.html","id":"inducing-sparsity-in-distilled-surrogate-models","dir":"Articles","previous_headings":"Model Distillation","what":"Inducing Sparsity in Distilled Surrogate Models","title":"Distillation Methods","text":"induce sparsity distilled surrogate models, can also introduce arguments weight-fitting process cv.glmnet specifying parameters params.cv.glmnet argument. argument list arguments function cv.glmnet can take. equivalent argument params.glment exists distill method user-specified fitting weights cv = F penalty factor. case, coefficient set 0, note coefficients sparse modell tend smaller original distilled model.","code":"# Sparse Model sparse_model <- distill(forest_interpret,                             cv = T,                             params.cv.glmnet = list(lower.limits = 0,                                                    intercept = F,                                                    alpha = 1)) print(distilled_model$weights) ##        Sepal.Width       Petal.Length        Petal.Width Species_versicolor  ##          1.4818192          1.3057638          0.7783864          0.9033819  ##  Species_virginica     Species_setosa  ##          0.7656621          0.8530705 print(sparse_model$weights) ##        Sepal.Width       Petal.Length        Petal.Width Species_versicolor  ##          1.1008288          1.3693586          0.9042907          0.6406511  ##  Species_virginica     Species_setosa  ##          0.2239083          0.5254830"},{"path":"/articles/model_distillation.html","id":"predictions-using-surrogate-models","dir":"Articles","previous_headings":"Model Distillation","what":"Predictions Using Surrogate Models","title":"Distillation Methods","text":"use predict function make new predictions distilled surrogate models. Note output surrogate model one-column dataframe new predictions. measured test set, see distilled models outperform original random forest model, indicating distilled models generalize better sample. varies based use-case. can compare closely distilled predictions match original predictions plotting :   Neither model matches exceptionally well original model’s predictions, shown plots. case, see regularized, sparse distilled model matches original random forest’s predictions better default settings, corroborates similar --sample performance. details distill method, please refer documentation provided “References” section.","code":"# make predictions original.preds <- predict(forest, test[,-1]) distill.preds <- predict(distilled_model, test[,-1])[,1] sparse.preds <- predict(sparse_model, test[,-1])[,1]  # compare MSE rmse <- function(preds){   return(sqrt(mean((test[,1] - preds)^2))) }  print(data.frame(original = rmse(original.preds),                  distill = rmse(distill.preds),                  distill.sparse = rmse(sparse.preds))) ##   original   distill distill.sparse ## 1 0.751415 0.7124756       0.740607 # create dataframe of data we'd like to plot plot.data <- data.frame(original.preds,                         distill.preds,                         sparse.preds)  # plots for both default distilled model and sparse model default.plot <- ggplot(data = plot.data, aes(x = original.preds,                                              y = distill.preds)) +                 geom_point() + geom_abline(col = \"red\")  sparse.plot <- ggplot(data = plot.data, aes(x = original.preds,                                              y = sparse.preds)) +                 geom_point() + geom_abline(col = \"red\")  plot(default.plot) plot(sparse.plot)"},{"path":"/articles/pdp_plots.html","id":"creating-pdp-plots","dir":"Articles","previous_headings":"","what":"Creating PDP Plots","title":"PDP Plots","text":"order use interpretability distillation methods Distillery package, machine learning model must wrapped Predictor object first. provides standardized interface getting predictions algorithm.","code":"# Load the required packages library(Distillery) library(Rforestry)  # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a random forest on the data set forest <- forestry(x=data[,-1],                    y=data[,1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")"},{"path":"/articles/pdp_plots.html","id":"creating-an-interpreter","dir":"Articles","previous_headings":"","what":"Creating an Interpreter","title":"PDP Plots","text":"can use standardized prediction wrapper create Interpreter, class holds PDP ALE functions model. can directly access partial dependence functions interpreter object, use create predictions.","code":"# Initialize an interpreter forest_interpret <- Interpreter$new(predictor = forest_predictor) # Make predictions using the Sepal.Width PDP function. # predictions <- forest_interpret$pdp.1d$Sepal.Width(seq(2,4, length.out = 20))"},{"path":"/articles/pdp_plots.html","id":"pdp-plots","dir":"Articles","previous_headings":"","what":"PDP Plots","title":"PDP Plots","text":"Given Interpreter object, can also create PDP plots using plot() method.  X axis plot displays histogram training data user can see PDP support training data. can also include ICE lines within PDP plots changing method plotting function.","code":"pdp_plots <-  plot(forest_interpret, method = \"pdp\", features = \"Sepal.Width\") plot(pdp_plots$Sepal.Width) pdp_plots <-  plot(forest_interpret, method = \"pdp+ice\", features = \"Sepal.Width\") plot(pdp_plots$Sepal.Width)"},{"path":"/articles/prediction_wrapper.html","id":"prediction-wrapper-support","dir":"Articles","previous_headings":"","what":"Prediction Wrapper Support","title":"Prediction Wrapper","text":"start using machine learning algorithm Distillery package prediction wrapper, wraps machine learning algorithm converts Predictor class object. Predictor wrapper requires single set predictions end, therefore users may need provide prediction functions based original algorithm hope wrap. page provides two key examples: predicting probabilities specific class categorical feature, specifying one’s prediction function.","code":""},{"path":"/articles/prediction_wrapper.html","id":"predictor-wrapper-with-categorical-features","dir":"Articles","previous_headings":"Prediction Wrapper Support","what":"Predictor Wrapper With Categorical Features","title":"Prediction Wrapper","text":"use Distillery categorical feature prediction, user specifies prediction task task = \"classification, chooses specific value categorical feature class argument, provide type argument prediction. , demonstrate example using multinomial logstic regression model predict likelihood iris observation “setosa” species. desired, see final predictions predicted probabiltiies observation “setosa” type iris.","code":"# Load the required packages library(Distillery) library(nnet)  # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a mutinomial logistic regression model on the data set multilog <- multinom(Species ~., data = data) ## # weights:  18 (10 variable) ## initial  value 164.791843  ## iter  10 value 16.177348 ## iter  20 value 7.111438 ## iter  30 value 6.182999 ## iter  40 value 5.984028 ## iter  50 value 5.961278 ## iter  60 value 5.954900 ## iter  70 value 5.951851 ## iter  80 value 5.950343 ## iter  90 value 5.949904 ## iter 100 value 5.949867 ## final  value 5.949867  ## stopped after 100 iterations head(predict(multilog, type = \"probs\")) ##      setosa   versicolor    virginica ## 1 1.0000000 1.526406e-09 2.716417e-36 ## 2 0.9999996 3.536476e-07 2.883729e-32 ## 3 1.0000000 4.443506e-08 6.103424e-34 ## 4 0.9999968 3.163905e-06 7.117010e-31 ## 5 1.0000000 1.102983e-09 1.289946e-36 ## 6 1.0000000 3.521573e-10 1.344907e-35 # Create a predictor wrapper for the model (specify task, class, type) setosa_predictor <- Predictor$new(model = multilog,                                   data=data,                                   y=\"Species\",                                   task = \"classification\",                                   class = \"setosa\",                                   type = \"probs\")  # Predictions returned for setosa probabilities head(predict(setosa_predictor, iris)) ##      setosa ## 1 1.0000000 ## 2 0.9999996 ## 3 1.0000000 ## 4 0.9999968 ## 5 1.0000000 ## 6 1.0000000"},{"path":"/articles/prediction_wrapper.html","id":"specifying-user-inputted-prediction-functiobs","dir":"Articles","previous_headings":"Prediction Wrapper Support","what":"Specifying User-Inputted Prediction Functiobs","title":"Prediction Wrapper","text":"generally, get single vector column predictions, may need specify prediction function . case, user can pass prediction function predict_func argument intialiizing Predictor object. provide example BART (Bayesian Additive Regression Tree) algorithm package dbarts. desired, user-specified prediction method input results predictions single vector one-column dataframe. details, please refer documentation Predictor class “References” section.","code":"library(dbarts) ## Warning: package 'dbarts' was built under R version 4.1.2 cat.index <- which(names(data) == \"Species\") # BART requires numerical features  # create a BART model bart.model <- bart(x.train = data[, -c(1, cat.index)],                    y.train = data[, 1],                    keeptrees = T,                    ndpost = 500,                    verbose = F)  # default predictions result in multiple columns predict(bart.model, data[, -c(1, cat.index)])[1:5, 1:5] ##          [,1]     [,2]     [,3]     [,4]     [,5] ## [1,] 4.894394 4.692147 4.967452 4.681489 4.948031 ## [2,] 4.899861 4.631130 4.889335 4.832738 4.877766 ## [3,] 5.057006 4.608528 4.792110 4.889669 5.003350 ## [4,] 4.925735 4.626869 4.932923 4.967804 4.968624 ## [5,] 5.054252 4.654580 4.905698 4.927613 4.964204 # create user-specified function predict_bart <- function(object, newdata){   return(colMeans(predict(object, newdata))) }  # initialize Predictor object for BART bart_predictor <- Predictor$new(model = bart.model,                                 data = data[, -cat.index],                                 predict.func = predict_bart,                                 y = \"Sepal.Length\",                                 task = \"regression\")  # predict with the Predictor object predict(bart_predictor, data[, -c(1, cat.index)])[1:5, ] ## [1] 5.064045 4.702024 4.784209 4.900565 5.058141"},{"path":"/articles/smoothing.html","id":"background","dir":"Articles","previous_headings":"","what":"Background","title":"Smoothing PDP + ALE Curves","text":"partial dependence function defined expectation regression function predictions value single feature marginally perturbed. feature \\(S\\) regression function \\(f\\), can write : \\[ PDP_S(x) := \\mathbb{E}_{X}\\left[f(X) \\mid X_S = x\\right] \\] practice estimate partial dependence function point \\(x\\) taking sample average predictions regression function training data set feature \\(X_S\\) set desired evaluation point \\(x\\). \\[ \\hat{PDP}_{S}\\left(x\\right)=\\frac{1}{n} \\sum_{=1}^{n} {f}\\left(X_{,X_s = x }\\right) \\] \\(X_{,X_s = x }\\) \\(\\)th training observation feature \\(S\\) set equal \\(x\\). training samples drawn ..d. sample true distribution \\(X\\), take expectation respect definition PDP, estimate unbiased true value PDP function \\(f\\) \\(S\\)th feature evaluated \\(x\\). Combining estimates many grid points, can plot estimated PDP function function \\(x\\). Sometimes may beneficial introduce bias point wise estimates PDP function order improve interpretability stability entire PDP function. One option use kernel smoothing smooth estimated PDP function values. Given independent features \\(x\\), outcomes \\(y\\), kernel function \\(K\\) bandwidth \\(h\\), Nadaraya–Watson kernel regression estimator given : \\[ \\widehat{m}_{h}(x)=\\frac{\\sum_{}^{n} K_{h}\\left(x-x_{}\\right) y_{}}{\\sum_{=1}^{n} K_{h}\\left(x-x_{}\\right)} \\] estimated point wise values PDP function, can apply kernel regression smooth estimated function. predictions smoothed PDP function given : \\[ \\hat{PDP}_{S, smooth}\\left(x\\right) =\\frac{\\sum_{\\X_{train}} K_{h}\\left(x-x_{}\\right) \\hat{PDP}_{S}\\left(x_i\\right) }{\\sum_{\\X_{train}} K_{h}\\left(x-x_{}\\right)} \\] implement method allow user specify desired kernel, \\(K\\), bandwidth \\(h\\).","code":""},{"path":"/articles/smoothing.html","id":"curve-smoothing","dir":"Articles","previous_headings":"","what":"Curve Smoothing","title":"Smoothing PDP + ALE Curves","text":"get smoothed plots PDP, ICE, ALE curves continuous features, also options smooth curves using stats:ksmooth package. may beneficial users want well-behaved curves plotting distillation. , set parameter smooth equal TRUE calling plot function, can set bandwidth, number points interpolate, type smoothing parameters smooth.binsize, smooth.npoints, smooth.type respectively. can compare smooth standard PDP plots model:   bandwidth, default maximum difference grid points given feature. type smoothing done default uses Gaussian kernel, number points double number grid points. setting bandwidth number points, one careful creating empty kernels. result NA values prompt user put different values parameters. can also smooth ALE ICE plots way:    details methods, please refer “References” tab, contains documentation methods discussed.","code":"library(MASS) library(distillML) suppressMessages(library(Rforestry)) ## Warning: package 'Rforestry' was built under R version 4.1.2 # Load in data  data(\"iris\") set.seed(491) data <- iris  # Train a random forest on the data set forest <- forestry(x=data[,-1],                    y=data[,1])  # Create a predictor wrapper for the forest forest_predictor <- Predictor$new(model = forest,                                   data=data,                                   y=\"Sepal.Length\",                                   task = \"regression\")  # We specify grid.size for clarity (grid.size = 50 by default) forest_interpreter <- Interpreter$new(forest_predictor) # Default smoothing options plot(forest_interpreter,      method = \"pdp\",      features = c(\"Sepal.Width\"),      smooth = T) ## $Sepal.Width # compare to unsmoothed plots plot(forest_interpreter,       method = \"pdp\",      features = c(\"Sepal.Width\")) ## $Sepal.Width # Smooth ICE plots plot(forest_interpreter,      features = c(\"Sepal.Width\"),      smooth = T,      method = \"pdp+ice\",      smooth.binsize = .1,      smooth.npoints = 500) ## $Sepal.Width # Smooth ALE plots plot(forest_interpreter,      features = c(\"Sepal.Width\"),      smooth = T,      method = \"ale\",      smooth.binsize = .2,      smooth.npoints = 500) ## $Sepal.Width # Standard ALE plots plot(forest_interpreter,      features = c(\"Sepal.Width\"),      method = \"ale\",      smooth = F) ## $Sepal.Width"},{"path":"/authors.html","id":null,"dir":"","previous_headings":"","what":"Authors","title":"Authors and Citation","text":"Brian Cho. Author. Theo Saarinen. Author, maintainer. Simon Walter. Author. Jasjeet Sekhon. Author.","code":""},{"path":"/authors.html","id":"citation","dir":"","previous_headings":"","what":"Citation","title":"Authors and Citation","text":"Cho B, Saarinen T, Walter S, Sekhon J (2022). distillML: Model Distillation Interpretability Methods Machine Learning Models. R package version 0.1.0.3, https://github.com/forestry-labs/distillML.","code":"@Manual{,   title = {distillML: Model Distillation and Interpretability Methods for Machine Learning Models},   author = {Brian Cho and Theo Saarinen and Simon Walter and Jasjeet Sekhon},   year = {2022},   note = {R package version 0.1.0.3},   url = {https://github.com/forestry-labs/distillML}, }"},{"path":"/index.html","id":"distillml-interpretable-machine-learning-methods-and-surrogate-model-methods","dir":"","previous_headings":"","what":"Model Distillation and Interpretability Methods for Machine Learning Models","title":"Model Distillation and Interpretability Methods for Machine Learning Models","text":"distillML provides several methods model distillation interpretability general black box machine learning models. package provides implementations partial dependence plot (PDP), individual conditional expectation (ICE), accumulated local effect (ALE) methods, model-agnostic interpretability methods (work supervised machine learning model). package also provides novel method building surrogate model approximates behavior initial algorithm. , provide simple example outlines use package. details surrogate distillation, advanced interpretability features, local surrogate methods, see articles provided page. documentation, see: https://forestry-labs.github.io/distillML/reference/index.html","code":""},{"path":"/index.html","id":"a-simple-example-predicting-carapace-width-of-leptograpsus-crabs","dir":"","previous_headings":"","what":"A Simple Example: Predicting Carapace Width of Leptograpsus Crabs","title":"Model Distillation and Interpretability Methods for Machine Learning Models","text":"Throughout section, provide tutorial using package random forest predictor Carapace Width Leptograpsus Crabs. demonstrate plot PDP, ICE, ALE curves machine learning interpretability, show build surrogate model approximates behavior initial random forest predictor.","code":""},{"path":"/index.html","id":"general-prediction-wrapper","dir":"","previous_headings":"A Simple Example: Predicting Carapace Width of Leptograpsus Crabs","what":"General Prediction Wrapper","title":"Model Distillation and Interpretability Methods for Machine Learning Models","text":"First load crabs data set. contains physical measurements several species crabs collected Fremantle, West Australia. can train random forest estimate Carapace Width crabs based features. order use interpretability features, must create Predictor class estimator want interpret. class standardizes predictions, tracks outcome feature, stores training data.","code":"library(MASS) library(distillML) library(Rforestry) library(ggplot2)  set.seed(491)  data <- MASS::crabs levels(data$sex) <- list(Male = \"M\", Female = \"F\") levels(data$sp) <- list(Orange = \"O\", Blue = \"B\") colnames(data) <- c(\"Species\",\"Sex\",\"Index\",\"Frontal Lobe\",                     \"Rear Width\", \"Carapace Length\",\"Carapace Width\",                     \"Body Depth\") # Get training data set set.seed(491) test_ind <- sample(1:nrow(data), nrow(data)%/%5) train_reg <- data[-test_ind,] test_reg <- data[test_ind,]  # Train a random forest on the data set forest <- forestry(x=train_reg[,-which(names(train_reg)==\"Carapace Width\")],                    y=train_reg[,which(names(train_reg)==\"Carapace Width\")])  # Create a predictor wrapper for the forest # this allows us to use a standard wrapper for querying any  # trained estimator forest_predictor <- Predictor$new(model = forest,                                    data=train_reg,                                    y=\"Carapace Width\",                                   task = \"regression\")"},{"path":"/index.html","id":"interpretability-wrapper","dir":"","previous_headings":"A Simple Example: Predicting Carapace Width of Leptograpsus Crabs","what":"Interpretability Wrapper","title":"Model Distillation and Interpretability Methods for Machine Learning Models","text":"initialized Predictor object forest, can pass Interpreter class. default, Interpreter class subsamples training data 1000 samples order speed computation interpretabilitiy methods. class provides names classes features, indicies sampled data points, lists univariate bivariate PDP functions, stores additional information plot settings. PDP functions stored two lists, one univariate PDP functions one bivariate PDP functions.feature, can retrieve pdp function selecting entry list feature name. can directly use PDP functions specifying values specific feature. functions return PDP curve’s values. univariate functions, specify values vector values. bivariate functions, input dataframe matrix two columns, row providing pair values column representing specific feature.","code":"forest_interpret <- Interpreter$new(predictor = forest_predictor)  print(forest_interpret) ## <Interpreter> ##   Public: ##     ale.grid: list ##     center.at: list ##     clone: function (deep = FALSE)  ##     data.points: 17 59 105 8 18 51 157 37 102 44 119 131 107 75 7 148 60  ... ##     feat.class: factor factor integer numeric numeric numeric numeric ##     features: Species Sex Index Frontal Lobe Rear Width Carapace Lengt ... ##     features.2d: data.frame ##     grid.points: list ##     grid.size: 50 ##     initialize: function (predictor = NULL, samples = 1000, data.points = NULL,  ##     pdp.1d: list ##     pdp.2d: list ##     predictor: Predictor, R6 ##     saved: list # univariate PDP  one_feat <- train_reg$`Frontal Lobe`[1:10] preds_pdp <- forest_interpret$pdp.1d$`Frontal Lobe`(one_feat) print(preds_pdp) ##  [1] 34.30249 34.41734 34.44234 34.44921 34.67518 35.00046 35.02284 35.11743 ##  [9] 35.47968 35.47968 # bivariate PDP two_feat <- cbind(train_reg$`Frontal Lobe`[1:10],                    train_reg$`Rear Width`[1:10]) preds_pdp_2d <- forest_interpret$pdp.2d$`Frontal Lobe`$`Rear Width`(two_feat) print(preds_pdp_2d) ##  [1] 31.86542 32.27242 32.33959 32.35324 33.07650 33.29917 33.40389 34.38326 ##  [9] 34.61258 34.78585"},{"path":"/index.html","id":"basic-plotting","dir":"","previous_headings":"A Simple Example: Predicting Carapace Width of Leptograpsus Crabs","what":"Basic Plotting","title":"Model Distillation and Interpretability Methods for Machine Learning Models","text":"univariate bivariate interpretability methods, can use plot method Interpreter class. univariate summaries model’s behavior, three main options: PDP, ICE, ALE curves. univariate plots feature, distillML includes histogram marginal distribution feature show support. plot specific curve given set feature, simply specify method parameter plot function, shown :     bivariate summary plots, package provides two distinct methods. Given continuous categorical feature, plot function provides conditional PDP curves, separates mean values based categorical feature value. two continuous features, plot function provides PDP heatmap. input pairs features plot, specify form two-column dataframe feature names, row represents single pair.   advanced plotting features, clustering ICE curves specifying number points plotted, please refer article “Advanced Plotting Features”.","code":"# plotting PDP functions plot(forest_interpret,      method = \"pdp\",      features = c(\"Frontal Lobe\", \"Rear Width\")) plot(forest_interpret,      method = \"ice\",      features = c(\"Frontal Lobe\", \"Rear Width\")) ## default option (does this without specifying method) plot(forest_interpret,      method = \"pdp+ice\",      features = c(\"Frontal Lobe\", \"Rear Width\")) plot(forest_interpret,      method = \"ale\",      features = c(\"Frontal Lobe\", \"Rear Width\")) plot(forest_interpret,      features.2d = data.frame(feat.1 = c(\"Frontal Lobe\", \"Frontal Lobe\"),                               feat.2 = c(\"Sex\", \"Rear Width\"))) ## $`Frontal Lobe.Sex` ##  ## $`Frontal Lobe.Rear Width`"},{"path":"/index.html","id":"local-surrogates","dir":"","previous_headings":"A Simple Example: Predicting Carapace Width of Leptograpsus Crabs","what":"Local Surrogates","title":"Model Distillation and Interpretability Methods for Machine Learning Models","text":"Even heatmap conditional plots, two dimensional summaries may difficult interpret. function localSurrogate provides local summary changes pair features affect predictions model providing simple decision tree summary. plots , left tree represents “Frontal Lobe” “Sex” pair, right tree represents “Frontal Lobe” “Rear Width” pair.  additional details localSurrogate method, specifying depth number trees weak learner, please refer article “Local Surrogate”.","code":"local.surr <- localSurrogate(forest_interpret,                              features.2d = data.frame(feat.1 = c(\"Frontal Lobe\",                                                                   \"Frontal Lobe\"),                                                       feat.2 = c(\"Sex\",                                                                   \"Rear Width\"))) plot(local.surr$models$`Frontal Lobe.Sex`) plot(local.surr$models$`Frontal Lobe.Rear Width`)"},{"path":"/index.html","id":"distillation-creating-the-default-surrogate-model","dir":"","previous_headings":"A Simple Example: Predicting Carapace Width of Leptograpsus Crabs","what":"Distillation: Creating the Default Surrogate Model","title":"Model Distillation and Interpretability Methods for Machine Learning Models","text":"package, also provide implementation new algorithm, creates linear recombination univariate PDP curves generate surrogate model. , use distill method interpeter object, returns surrogate model. surrogate model, can make predictions, compare original predictions random forest surrogate model .  additional details creating distilled surrogate models, please refer article “Distillation Methods”.","code":"forest_surrogate <- distill(forest_interpret)  predictions_forest <- predict(forest,                               test_reg[,-which(names(test_reg) == \"Carapace Width\")])  # surrogate predictions are returned as a one-column dataframe predictions_surrogate <- predict(forest_surrogate,                                  test_reg[,-which(names(test_reg) == \"Carapace Width\")])  plot.comparison <- data.frame(original = predictions_forest,                               surrogate = predictions_surrogate[,1]) ggplot(data = plot.comparison, aes(x = original, y = surrogate)) +    geom_point() + geom_abline(col = \"red\")"},{"path":"/reference/Interpreter.html","id":null,"dir":"Reference","previous_headings":"","what":"Interpreter class description — Interpreter","title":"Interpreter class description — Interpreter","text":"wrapper class based predictor object examining predictions model respect one two features. two methods interpreting model based one two features partial dependence plots (PDP), averages marginal distribution predictions model, accumulated local effects (ALE) functions averages conditional distribution predictions model. necessary argument Predictor object. arguments optional, may useful specify number samples specific data points (data.points) training data large. can greatly reduce time computation. output, model returns interpreter object two lists functions: one interpreting single feature's role black-box model, intepreting pair features' role black-box model. interpretability functions built possible feature (pair features). functions return vector averaged predictions equal length number values (number rows) input function.","code":""},{"path":"/reference/Interpreter.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Interpreter class description — Interpreter","text":"class wraps Predictor object application different interpretability methods. usage examples, please refer README document.","code":""},{"path":"/reference/Interpreter.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Interpreter class description — Interpreter","text":"predictor Predictor object contains model user wants query. parameter required initialize Interpreter object. entries vector must match column names `data` parameter Predictor object. features optional list single features want create PDP functions . features.2d two column data frame contains pairs names want create 2D PDP functions . entries data frame must match column names `data` parameter Predictor object. data.points vector indices data points training data frame used observations creating PDP/ICE/ALE plots. training data large, can greatly reduce required computation pass downsampled subset training data pdp function construction. Alternatively, one interested understanding model predictions specific subgroup, indices observations given subgroup can passed . pdp.1d List functions giving single feature PDP interpretations model. pdp.2d List functions giving two-feature PDP interpretations model feat.class vector contains class feature (categorical continuous) center.value(s) center feature plots . list equal length length features. grid.points list vectors containing grid points use predictions PDP ICE plots. ALE plots, use quantile-based methods depend distribution training data. grid.size number grid points plot continuous feature. parameter sets number grid points PDP, ICE, ALE plots. saved list caches previous calculations 1-D ICE plots, 1-D PDP plots, 2-D PDP plots, grid points building distilled model. saves uncentered calculations. ale.grid list caches saved predictions ALE plots","code":""},{"path":[]},{"path":"/reference/Interpreter.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Interpreter class description — Interpreter","text":"Interpreter$new() Interpreter$clone()","code":""},{"path":[]},{"path":"/reference/Interpreter.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpreter class description — Interpreter","text":"","code":"Interpreter$new(   predictor = NULL,   samples = 1000,   data.points = NULL,   grid.size = 50 )"},{"path":"/reference/Interpreter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpreter class description — Interpreter","text":"predictor Predictor object contains model user wants query. parameter required initialize Interpreter object. entries vector must match column names `data` parameter Predictor object. samples number observations used interpretability method. number given, default set minimum 1000 number rows training data set. Rows missing values excluded sampled. data.points indices data points used PDP/ALE. overwrites \"samples\" parameter . grid.size number grid points used create PDP, ICE, ALE plots feature.","code":""},{"path":"/reference/Interpreter.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Interpreter class description — Interpreter","text":"`Interpreter` object.","code":""},{"path":"/reference/Interpreter.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Interpreter class description — Interpreter","text":"objects class cloneable method.","code":""},{"path":"/reference/Interpreter.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Interpreter class description — Interpreter","text":"","code":"Interpreter$clone(deep = FALSE)"},{"path":"/reference/Interpreter.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Interpreter class description — Interpreter","text":"deep Whether make deep clone.","code":""},{"path":"/reference/Interpreter.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Interpreter class description — Interpreter","text":"","code":"library(distillML) library(Rforestry) #> Warning: package ‘Rforestry’ was built under R version 4.1.2 #> ##  #> ##  Rforestry (Version 0.9.0.95, Build Date: R 4.1.2; x86_64-apple-darwin17.0; 2022-03-10 13:19:39 UTC; unix) #> ##  See https://github.com/forestry-labs for additional documentation. #> ##  Please cite software as: #> ##    Soren R. Kunzel, Theo F. Saarinen, Edward W. Liu, Jasjeet S. Sekhon. 2019. #> ##    ''Linear Aggregation in Tree-based Estimators.'' arXiv preprint  #> ##    arXiv:1906.06463. https://arxiv.org/abs/1906.06463  #> ## set.seed(491) data <- MASS::crabs  levels(data$sex) <- list(Male = \"M\", Female = \"F\") levels(data$sp) <- list(Orange = \"O\", Blue = \"B\") colnames(data) <- c(\"Species\",\"Sex\",\"Index\",\"Frontal Lobe\", \"Rear Width\", \"Carapace Length\",\"Carapace Width\",\"Body Depth\")  test_ind <- sample(1:nrow(data), nrow(data)%/%5) train_reg <- data[-test_ind,] test_reg <- data[test_ind,]   forest <- forestry(x=train_reg[,-which(names(train_reg)==\"Carapace Width\")], y=train_reg[,which(names(train_reg)==\"Carapace Width\")])  forest_predictor <- Predictor$new(model = forest, data=train_reg, y=\"Carapace Width\", task = \"regression\")  forest_interpret <- Interpreter$new(predictor = forest_predictor)"},{"path":"/reference/Predictor.html","id":null,"dir":"Reference","previous_headings":"","what":"Predictor class description — Predictor","title":"Predictor class description — Predictor","text":"wrapper class generic ML algorithms (xgboost, RF, BART, rpart, etc.) order standardize predictions given different algorithms compatible interpretability functions. necessary variables model, data, y. variables optional, depend use cases. Type used prediction function specified. outputs algorithm must values regression, probabilities classification. classification problems two categories, output comes vectors probabilities specified \"class\" category. ML interpretability, types predictions (ex: predictions spit factor) allowed.","code":""},{"path":"/reference/Predictor.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Predictor class description — Predictor","text":"class wraps machine learning model order provide  standardized method predictions different models. prediction method must constructed, optional argument type","code":""},{"path":"/reference/Predictor.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Predictor class description — Predictor","text":"data training data used training model. data frame matching data frame model given training, includes label outcome. model object corresponding trained model want make Predictor object . model generic predict method, user provide custom predict function accepts data frame. task prediction task model trained perform (`classification` `regression`). class class get predictions. specify get predictions (probabilites) observation specific class (e.g. Male Female). parameter necessary classification predictions single vector predictions. prediction.function optional parameter model generic prediction function. take data frame return vector predictions observation data frame. y name outcome feature `data` data frame.","code":""},{"path":[]},{"path":"/reference/Predictor.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Predictor class description — Predictor","text":"Predictor$new() Predictor$clone()","code":""},{"path":[]},{"path":"/reference/Predictor.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictor class description — Predictor","text":"","code":"Predictor$new(   model = NULL,   data = NULL,   predict.func = NULL,   y = NULL,   task = NULL,   class = NULL,   type = NULL )"},{"path":"/reference/Predictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictor class description — Predictor","text":"model object corresponding trained model want make Predictor object . model generic predict method, user provide custom predict function accepts data frame. data training data used training model. data frame matching data frame model given training, including label outcome. predict.func optional parameter model generic prediction function. take data frame return vector predictions observation data frame. y name outcome feature `data` data frame. task prediction task model trained perform (`classification` `regression`). class class get predictions. specify get predictions (probabilites) observation specific class (e.g. Male Female). parameter necessary classification predictions single vector predictions. type type predictions done (.e. 'response' predicted probabliities classification). feature used predict.func specified.","code":""},{"path":"/reference/Predictor.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Predictor class description — Predictor","text":"`Predictor` object.","code":""},{"path":"/reference/Predictor.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Predictor class description — Predictor","text":"objects class cloneable method.","code":""},{"path":"/reference/Predictor.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Predictor class description — Predictor","text":"","code":"Predictor$clone(deep = FALSE)"},{"path":"/reference/Predictor.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predictor class description — Predictor","text":"deep Whether make deep clone.","code":""},{"path":"/reference/Predictor.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Predictor class description — Predictor","text":"","code":"library(distillML) library(Rforestry) set.seed(491) data <- MASS::crabs  levels(data$sex) <- list(Male = \"M\", Female = \"F\") levels(data$sp) <- list(Orange = \"O\", Blue = \"B\") colnames(data) <- c(\"Species\",\"Sex\",\"Index\",\"Frontal Lobe\", \"Rear Width\", \"Carapace Length\",\"Carapace Width\",\"Body Depth\")  test_ind <- sample(1:nrow(data), nrow(data)%/%5) train_reg <- data[-test_ind,] test_reg <- data[test_ind,]   forest <- forestry(x=train_reg[,-which(names(train_reg)==\"Carapace Width\")], y=train_reg[,which(names(train_reg)==\"Carapace Width\")])  forest_predictor <- Predictor$new(model = forest, data=train_reg, y=\"Carapace Width\", task = \"regression\")"},{"path":"/reference/Surrogate.html","id":null,"dir":"Reference","previous_headings":"","what":"Surrogate class description — Surrogate","title":"Surrogate class description — Surrogate","text":"class distilled surrogate models.","code":""},{"path":"/reference/Surrogate.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Surrogate class description — Surrogate","text":"initalize class . automatically created       distill function interpreter class.","code":""},{"path":"/reference/Surrogate.html","id":"public-fields","dir":"Reference","previous_headings":"","what":"Public fields","title":"Surrogate class description — Surrogate","text":"interpreter interpreter object use standardized wrapper model features indices features data used surrogate model weights weights used recombine PDPs surrogate original model intercept intercept term use predictions feature.centers center value features determined model center.mean Boolean value determines whether use mean-centered data predictions grid list PDPS determine prediction. snap.grid Boolean determines whether use grid.points","code":""},{"path":[]},{"path":"/reference/Surrogate.html","id":"public-methods","dir":"Reference","previous_headings":"","what":"Public methods","title":"Surrogate class description — Surrogate","text":"Surrogate$new() Surrogate$clone()","code":""},{"path":[]},{"path":"/reference/Surrogate.html","id":"usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Surrogate class description — Surrogate","text":"","code":"Surrogate$new(   interpreter,   features,   weights,   intercept,   feature.centers,   center.mean,   grid,   snap.grid )"},{"path":"/reference/Surrogate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surrogate class description — Surrogate","text":"interpreter interpreter object want build surrogate model . features indices features training data used surrogate model weights weights given feature surrogate model fit. intercept baseline value. uncentered, 0, centered, mean predictions original model training data. feature.centers baseline value effect feature. uncentered, 0. center.mean boolean value shows whether model centered uncentered model grid list dataframes containing pre-calculated values used generate predictions snap.grid TRUE snap.grid Boolean determines use previously calculated values re-predict using functions.","code":""},{"path":"/reference/Surrogate.html","id":"returns","dir":"Reference","previous_headings":"","what":"Returns","title":"Surrogate class description — Surrogate","text":"surrogate model object can use predictions","code":""},{"path":"/reference/Surrogate.html","id":"method-clone-","dir":"Reference","previous_headings":"","what":"Method clone()","title":"Surrogate class description — Surrogate","text":"objects class cloneable method.","code":""},{"path":"/reference/Surrogate.html","id":"usage-1","dir":"Reference","previous_headings":"","what":"Usage","title":"Surrogate class description — Surrogate","text":"","code":"Surrogate$clone(deep = FALSE)"},{"path":"/reference/Surrogate.html","id":"arguments-1","dir":"Reference","previous_headings":"","what":"Arguments","title":"Surrogate class description — Surrogate","text":"deep Whether make deep clone.","code":""},{"path":"/reference/Surrogate.html","id":"ref-examples","dir":"Reference","previous_headings":"","what":"Examples","title":"Surrogate class description — Surrogate","text":"","code":"library(distillML) library(Rforestry) set.seed(491) data <- MASS::crabs  levels(data$sex) <- list(Male = \"M\", Female = \"F\") levels(data$sp) <- list(Orange = \"O\", Blue = \"B\") colnames(data) <- c(\"Species\",\"Sex\",\"Index\",\"Frontal Lobe\", \"Rear Width\", \"Carapace Length\",\"Carapace Width\",\"Body Depth\")  test_ind <- sample(1:nrow(data), 180) train_reg <- data[-test_ind,] test_reg <- data[test_ind,]   forest <- forestry(x=train_reg[,-which(names(train_reg)==\"Carapace Width\")], y=train_reg[,which(names(train_reg)==\"Carapace Width\")])  forest_predictor <- Predictor$new(model = forest, data=train_reg, y=\"Carapace Width\", task = \"regression\")  forest_interpret <- Interpreter$new(predictor = forest_predictor)  # Both initializations of a surrogate class result in the same surrogate model surrogate.model <- distill(forest_interpret) surrogate.model <- distill(forest_interpret,                            center.mean = TRUE,                            features = 1:length(forest_interpret$features),                            cv = FALSE,                            snap.grid = TRUE,                            snap.train = TRUE)"},{"path":"/reference/ale.html","id":null,"dir":"Reference","previous_headings":"","what":"Constructs an ALE for a model. — ale","title":"Constructs an ALE for a model. — ale","text":"Constructs ALE model.","code":""},{"path":"/reference/ale.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Constructs an ALE for a model. — ale","text":"","code":"ale(   predict_function,   num_grid_points,   training_data,   variable_names,   center = \"zero\",   grid_points,   window_size )"},{"path":"/reference/ale.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Constructs an ALE for a model. — ale","text":"predict_function function taking single tibble argument returning model predictions corresponding tibble. num_grid_points number grid_points construct ALE training_data training data used fit model variable_names vector feature names training data ALE required. center one \"uncentered\" meaning plots centered, \"mean\" meaning plots centered mean \"zero\" meaning ALE passes origin. using center == \"zero\" recommend setting window_size otherwise smaller possibly empty set used compute ALE zero. grid_points grid points use AlE calculation. window_size fraction data (zero one) used compute ALE point.","code":""},{"path":"/reference/build.grid.html","id":null,"dir":"Reference","previous_headings":"","what":"Build grid used for weights in distilled surrogate model — build.grid","title":"Build grid used for weights in distilled surrogate model — build.grid","text":"dataframe storing true predictions PDP predictions","code":""},{"path":"/reference/build.grid.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Build grid used for weights in distilled surrogate model — build.grid","text":"","code":"build.grid(object, feat.ind = 1:length(object$features))"},{"path":"/reference/build.grid.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Build grid used for weights in distilled surrogate model — build.grid","text":"object Interpreter object feat.ind indices features Interpreter's features want include PDP functions distilled model.","code":""},{"path":"/reference/build.grid.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Build grid used for weights in distilled surrogate model — build.grid","text":"dataframe used find weights regression (one-hot encoding         categorical features)","code":""},{"path":"/reference/build.grid.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Build grid used for weights in distilled surrogate model — build.grid","text":"function mainly used subroutine distill function. include public function allow users create weights surrogate functions outside implemented method.","code":""},{"path":"/reference/center.preds.html","id":null,"dir":"Reference","previous_headings":"","what":"Centers the predicted values for 1-d ICE and PDP plots or 2-d PDP plots — center.preds","title":"Centers the predicted values for 1-d ICE and PDP plots or 2-d PDP plots — center.preds","text":"Given specified 'center.' values Interpreter object,              function centers plots Interpreter object              specified type plot.","code":""},{"path":"/reference/center.preds.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Centers the predicted values for 1-d ICE and PDP plots or 2-d PDP plots — center.preds","text":"","code":"center.preds(object, features = NULL, plot.type, feats.2d = NULL)"},{"path":"/reference/center.preds.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Centers the predicted values for 1-d ICE and PDP plots or 2-d PDP plots — center.preds","text":"object Interpreter object use features vector names 1-D features want center plot.type type plot user wants center predictions . one either \"ICE\", \"PDP.1D\", \"PDP.2D\" feats.2d 2-column dataframe matrix gives first variable first column, second variable next. number rows equal number 2-D PDPs one like center.","code":""},{"path":"/reference/center.preds.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Centers the predicted values for 1-d ICE and PDP plots or 2-d PDP plots — center.preds","text":"list centered data frame/matrix values plot","code":""},{"path":"/reference/center.preds.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Centers the predicted values for 1-d ICE and PDP plots or 2-d PDP plots — center.preds","text":"center.preds","code":""},{"path":"/reference/center.preds.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Centers the predicted values for 1-d ICE and PDP plots or 2-d PDP plots — center.preds","text":"function mainly used examine exact values plot plot centered. Note function called calling one various predict functions matches 'plot.type' parameter 'save' equal TRUE.","code":""},{"path":"/reference/distill.html","id":null,"dir":"Reference","previous_headings":"","what":"Builds surrogate model from an interpreter object based on the univariate\n  PDP functions of the original model. — distill","title":"Builds surrogate model from an interpreter object based on the univariate\n  PDP functions of the original model. — distill","text":"Builds surrogate model PDP functions","code":""},{"path":"/reference/distill.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Builds surrogate model from an interpreter object based on the univariate\n  PDP functions of the original model. — distill","text":"","code":"distill(   object,   center.mean = T,   features = 1:length(object$features),   cv = F,   snap.grid = T,   snap.train = T,   params.glmnet = list(),   params.cv.glmnet = list() )"},{"path":"/reference/distill.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Builds surrogate model from an interpreter object based on the univariate\n  PDP functions of the original model. — distill","text":"object Interpreter object center.mean Boolean value determines whether center column predictions respective means. Default TRUE features indices features Interpreter's features want include PDP functions distilled model. cv Boolean indicates whether want cross-validate fitted coefficients regularizer. done regularizing coefficients. snap.grid Boolean function determines whether model recalculates value predicted uses approximation previous calculations. parameter set TRUE, approximate predicted values prevoius calculations. Default TRUE. snap.train Boolean determines whether use training data equally spaced grid points. default, true, means snap grid points determined training data's marginal distribution. params.glmnet Optional list parameters pass glmnet fitting PDP curves resemble original predictions. specifying parameters, one can lasso ridge regression. params.cv.glmnet Optional list parameters pass cv.glmnet fitting PDP curves resemble original predictions. specifying parameters, one can lasso ridge regression.","code":""},{"path":"/reference/distill.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Builds surrogate model from an interpreter object based on the univariate\n  PDP functions of the original model. — distill","text":"surrogate class object can used predictions","code":""},{"path":"/reference/distill.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Builds surrogate model from an interpreter object based on the univariate\n  PDP functions of the original model. — distill","text":"details, please refer vignette method, includes usage examples.","code":""},{"path":"/reference/localSurrogate.html","id":null,"dir":"Reference","previous_headings":"","what":"Given a interpreter object with at least one pair of features,\n  create a small surrogate model for the two features using the PDP function\n  as the output and the two features as the independent variables. — localSurrogate","title":"Given a interpreter object with at least one pair of features,\n  create a small surrogate model for the two features using the PDP function\n  as the output and the two features as the independent variables. — localSurrogate","text":"Plots returns Rforestry object single tree explaining   PDP surface.","code":""},{"path":"/reference/localSurrogate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Given a interpreter object with at least one pair of features,\n  create a small surrogate model for the two features using the PDP function\n  as the output and the two features as the independent variables. — localSurrogate","text":"","code":"localSurrogate(   object,   features.2d = NULL,   interact = FALSE,   params.forestry = list() )"},{"path":"/reference/localSurrogate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Given a interpreter object with at least one pair of features,\n  create a small surrogate model for the two features using the PDP function\n  as the output and the two features as the independent variables. — localSurrogate","text":"object Interpreter object make plots + surrogate . features.2d two-column dataframe pairs features make local surrogates . row represents pair features, names features entries. interact indicator specifying surrogate model also given interaction terms create surrogate models . Default FALSE. params.forestry Optional list parameters pass surrogate model. Defaults standard Rforestry parameters ntree = 1 maxDepth = 2.","code":""},{"path":"/reference/localSurrogate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Given a interpreter object with at least one pair of features,\n  create a small surrogate model for the two features using the PDP function\n  as the output and the two features as the independent variables. — localSurrogate","text":"list two distinct lists: one list contains local surrogate models,         containing 2-D PDP plots specified features.","code":""},{"path":"/reference/local_effect.html","id":null,"dir":"Reference","previous_headings":"","what":"Local effect gives the local effect on the predictions of a model\nin the window around the set_value — local_effect","title":"Local effect gives the local effect on the predictions of a model\nin the window around the set_value — local_effect","text":"Parameters:     @param variable_name - variable want perturb calculate local effect","code":""},{"path":"/reference/local_effect.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Local effect gives the local effect on the predictions of a model\nin the window around the set_value — local_effect","text":"","code":"local_effect(   variable_name,   lower_limit,   upper_limit,   set_value,   window_size,   training_data,   predict_function )"},{"path":"/reference/local_effect.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Local effect gives the local effect on the predictions of a model\nin the window around the set_value — local_effect","text":"@param lower_limit - lower limit variable want use @param upper_limit - upper limit variable want use @param set_value - value want perturb variable around @param window_size - optional parameter size window around                   variable perturb predict @param training_data - training data use make predictions @param predict_function - prediction function use make predictions model Return:     single value mean local effect peturbation     predictions model.","code":""},{"path":"/reference/plot-Interpreter.html","id":null,"dir":"Reference","previous_headings":"","what":"Plotting method for Interpretor model — plot-Interpreter","title":"Plotting method for Interpretor model — plot-Interpreter","text":"Plots PDP, ALE, ICE plots Interpreter object","code":""},{"path":"/reference/plot-Interpreter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Plotting method for Interpretor model — plot-Interpreter","text":"","code":"# S3 method for Interpreter plot(   x,   method = \"pdp+ice\",   features = NULL,   features.2d = NULL,   clusters = NULL,   clusterType = \"preds\",   smooth = FALSE,   smooth.binsize = NULL,   smooth.type = \"normal\",   smooth.npoints = 2 * x$grid.size,   ... )"},{"path":"/reference/plot-Interpreter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Plotting method for Interpretor model — plot-Interpreter","text":"x Interpreter object generate plots method type plot want generate. Must one \"ice\", \"pdp+ice\", \"pdp\", \"ale\" features vector feature names want produce 1-D plots . features.2d 2-D features want produce plots arguments. two-column dataframe pairs features make local surrogates . row represents pair features, names features entries.'method' parameter set \"ale\", argument used. clusters number clusters cluster ICE predictions . NULL, one must use method \"ice\". clusterType indicator specifying method use clustering. possible options \"preds\", \"gradient\". \"preds\" used, clusters determined running K means predictions ICE functions. \"gradient\" option used, clusters determined running K means numerical gradient predictions ICE functions. NULL, one must use method \"ice\". smooth binary variable determine whether smoothen plots PDP, ICE, ALE curves continuous variables. smooth.binsize bandwidth kernels. scaled quartiles 0.25 * bandwidth. default, set maximum difference minimum maximum grid points. smooth.type type kernel used. Users can input either strings \"box\" \"normal\". default \"normal\". smooth.npoints number points returned using kernel method. default, twice number grid points feature. ... Additiional parameters pass plot function","code":""},{"path":"/reference/plot-Interpreter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Plotting method for Interpretor model — plot-Interpreter","text":"list plots 1-d features 2-d features. 2-d features         one continuous one categorical feature, plot linear plot         continuous feature group colors representing categorical feature.         two continuous features, plot heatmap shade representing         value outcome.","code":""},{"path":"/reference/predict-Predictor.html","id":null,"dir":"Reference","previous_headings":"","what":"Predict method for Predictor class — predict-Predictor","title":"Predict method for Predictor class — predict-Predictor","text":"Gives single column predictions model  wrapped Predictor object","code":""},{"path":"/reference/predict-Predictor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Predict method for Predictor class — predict-Predictor","text":"","code":"# S3 method for Predictor predict(object, newdata, ...)"},{"path":"/reference/predict-Predictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Predict method for Predictor class — predict-Predictor","text":"object Predictor object use make predictions. newdata data frame use independent features prediction. ... Additional arguments passed model predict function. instance, can different aggregation options (aggregation = \"oob\") accepted prediction function model.","code":""},{"path":"/reference/predict-Predictor.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Predict method for Predictor class — predict-Predictor","text":"data frame single column containing predictions  row newdata data frame.","code":""},{"path":"/reference/predict-Surrogate.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction method for the distilled surrogate model — predict-Surrogate","title":"Prediction method for the distilled surrogate model — predict-Surrogate","text":"Predicts outputs given new data","code":""},{"path":"/reference/predict-Surrogate.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction method for the distilled surrogate model — predict-Surrogate","text":"","code":"# S3 method for Surrogate predict(object, newdata, ...)"},{"path":"/reference/predict-Surrogate.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction method for the distilled surrogate model — predict-Surrogate","text":"object surrogate object distilled interpreter newdata dataframe use predictions ... Additional parameters pass predict","code":""},{"path":"/reference/predict-Surrogate.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction method for the distilled surrogate model — predict-Surrogate","text":"one-column dataframe surrogate model's predictions","code":""},{"path":"/reference/predict_ALE.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction function for the ALE plots — predict_ALE","title":"Prediction function for the ALE plots — predict_ALE","text":"Prediction function ALE plots","code":""},{"path":"/reference/predict_ALE.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction function for the ALE plots — predict_ALE","text":"","code":"predict_ALE(x, feature, training_data, save = T)"},{"path":"/reference/predict_ALE.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction function for the ALE plots — predict_ALE","text":"x interpreter object feature feature build ALE (must continuous) training_data training data use order build ALE save Boolean save ALE predictions","code":""},{"path":"/reference/predict_ALE.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction function for the ALE plots — predict_ALE","text":"tibble contains ALE predictions given values","code":""},{"path":"/reference/predict_ICE.Plotter.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction Function for ICE Plots — predict_ICE.Plotter","title":"Prediction Function for ICE Plots — predict_ICE.Plotter","text":"Gives predictions point grid.","code":""},{"path":"/reference/predict_ICE.Plotter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction Function for ICE Plots — predict_ICE.Plotter","text":"","code":"predict_ICE.Plotter(object, features = NULL, save = TRUE)"},{"path":"/reference/predict_ICE.Plotter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction Function for ICE Plots — predict_ICE.Plotter","text":"object Interpeter object use. features vector names features predict ICE plots save boolean indicator indicate whether calculations saved interpreter object . can help reduce computation ICE functions used many times, requires additional memory store predictions. default, TRUE.","code":""},{"path":"/reference/predict_ICE.Plotter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction Function for ICE Plots — predict_ICE.Plotter","text":"list data frames, one feature. data frame, first         column contains grid values feature, subsequent         column single observation corresponding prediction model         given feature set grid point value.","code":""},{"path":"/reference/predict_ICE.Plotter.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Prediction Function for ICE Plots — predict_ICE.Plotter","text":"method meant primarily used find exact values ICE curves plotted. Note PDP curve plotted, returned object function saved predictions plotting curve, rather recalculation values.","code":""},{"path":"/reference/predict_PDP.1D.Plotter.html","id":null,"dir":"Reference","previous_headings":"","what":"Prediction Function for PDP Plots — predict_PDP.1D.Plotter","title":"Prediction Function for PDP Plots — predict_PDP.1D.Plotter","text":"Gives prediction curve specified features              plotter object","code":""},{"path":"/reference/predict_PDP.1D.Plotter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Prediction Function for PDP Plots — predict_PDP.1D.Plotter","text":"","code":"predict_PDP.1D.Plotter(object, features = NULL, save = TRUE)"},{"path":"/reference/predict_PDP.1D.Plotter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Prediction Function for PDP Plots — predict_PDP.1D.Plotter","text":"object Interpreter object plot PDP curves . features vector names features predict ICE plots save boolean indicator indicate whether calculations saved interpreter object . can help reduce computation PDP functions used many times, requires additional memory store predictions. default, set TRUE.","code":""},{"path":"/reference/predict_PDP.1D.Plotter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Prediction Function for PDP Plots — predict_PDP.1D.Plotter","text":"list data frames grid points PDP prediction values         feature object","code":""},{"path":"/reference/predict_PDP.1D.Plotter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Prediction Function for PDP Plots — predict_PDP.1D.Plotter","text":"predict_PDP.1D.Plotter","code":""},{"path":"/reference/predict_PDP.1D.Plotter.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Prediction Function for PDP Plots — predict_PDP.1D.Plotter","text":"method meant primarily used find exact values 1-D PDP curves plotted. Note PDP curve plotted, returned object function saved predictions plotting curve, rather recalculation values.","code":""},{"path":"/reference/predict_PDP.2D.Plotter.html","id":null,"dir":"Reference","previous_headings":"","what":"Two Dimensional Prediction Curve for PDP Plots — predict_PDP.2D.Plotter","title":"Two Dimensional Prediction Curve for PDP Plots — predict_PDP.2D.Plotter","text":"Gives prediction surface specified feature pairs              interpreter object (features.2d)","code":""},{"path":"/reference/predict_PDP.2D.Plotter.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Two Dimensional Prediction Curve for PDP Plots — predict_PDP.2D.Plotter","text":"","code":"predict_PDP.2D.Plotter(object, feat.2d, save = TRUE)"},{"path":"/reference/predict_PDP.2D.Plotter.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Two Dimensional Prediction Curve for PDP Plots — predict_PDP.2D.Plotter","text":"object Interpreter object use. feat.2d 2-column dataframe matrix gives first variable first column, second variable next. number rows equal number 2-D PDPs one like. save boolean indicator indicate whether calculations saved interpreter object . can help reduce computation PDP functions used many times, requires additional memory store predictions. default, set TRUE.","code":""},{"path":"/reference/predict_PDP.2D.Plotter.html","id":"value","dir":"Reference","previous_headings":"","what":"Value","title":"Two Dimensional Prediction Curve for PDP Plots — predict_PDP.2D.Plotter","text":"list data frames pair features.2d. data frame         contains columns corresponding grid points two selected         features column corresponding predictions model         given combination grid points.","code":""},{"path":"/reference/predict_PDP.2D.Plotter.html","id":"details","dir":"Reference","previous_headings":"","what":"Details","title":"Two Dimensional Prediction Curve for PDP Plots — predict_PDP.2D.Plotter","text":"predict_PDP.2D.Plotter","code":""},{"path":"/reference/predict_PDP.2D.Plotter.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Two Dimensional Prediction Curve for PDP Plots — predict_PDP.2D.Plotter","text":"method meant primarily used find exact values 2-D PDP curves heatmap plotted. Note PDP curve plotted, returned object function saved predictions plotting curve, rather recalculation values.","code":""},{"path":"/reference/print-Predictor.html","id":null,"dir":"Reference","previous_headings":"","what":"The Printing method for Predictor class — print-Predictor","title":"The Printing method for Predictor class — print-Predictor","text":"Prints task instance Predictor class.","code":""},{"path":"/reference/print-Predictor.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"The Printing method for Predictor class — print-Predictor","text":"","code":"# S3 method for Predictor print(x, ...)"},{"path":"/reference/print-Predictor.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"The Printing method for Predictor class — print-Predictor","text":"x Predictor object print ... Additional arguments passed print function.","code":""},{"path":"/reference/set.center.at.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets a new center in the PDP and ICE plots made by an Interpreter — set.center.at","title":"Sets a new center in the PDP and ICE plots made by an Interpreter — set.center.at","text":"Method setting center value specific feature","code":""},{"path":"/reference/set.center.at.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets a new center in the PDP and ICE plots made by an Interpreter — set.center.at","text":"","code":"set.center.at(object, feature, value)"},{"path":"/reference/set.center.at.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets a new center in the PDP and ICE plots made by an Interpreter — set.center.at","text":"object Interpreter class want recenter plots . feature name feature set grid points . value new value use plots specified feature centered . Must match type feature (factor level continuous value range specified feature).","code":""},{"path":"/reference/set.center.at.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sets a new center in the PDP and ICE plots made by an Interpreter — set.center.at","text":"Unlike grid predictions, center.values modify previous saved calculations. Therefore, change remove previously calculated, saved data. center values simply plots made interpreter object, rather distilled model.","code":""},{"path":"/reference/set.grid.points.html","id":null,"dir":"Reference","previous_headings":"","what":"Sets grid points used for plotting PDP and ICE plots — set.grid.points","title":"Sets grid points used for plotting PDP and ICE plots — set.grid.points","text":"Method setting grid points specific feature plot","code":""},{"path":"/reference/set.grid.points.html","id":"ref-usage","dir":"Reference","previous_headings":"","what":"Usage","title":"Sets grid points used for plotting PDP and ICE plots — set.grid.points","text":"","code":"set.grid.points(object, feature, values)"},{"path":"/reference/set.grid.points.html","id":"arguments","dir":"Reference","previous_headings":"","what":"Arguments","title":"Sets grid points used for plotting PDP and ICE plots — set.grid.points","text":"object Interpreter class want modify grid points . feature name feature set grid points . values set new values used grid points selected feature. Must vector entries range feature values training set must match type given feature (either vector factor levels vector continuous feature values). Note center must within range new grid points continuous features.","code":""},{"path":"/reference/set.grid.points.html","id":"note","dir":"Reference","previous_headings":"","what":"Note","title":"Sets grid points used for plotting PDP and ICE plots — set.grid.points","text":"grid points determine calculations performed PDP/ICE functions, changing grid points remove previously calculated values 'Interpreter' object. 1-D ICE PDP plot, remove previous calculations given feature. 2-D PDP calcuations, remove plots include given feature features. Note set grid points apply PDP ICE plots, ALE plots grid points determined distribution training data.","code":""}]
