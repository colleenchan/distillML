---
title: "Prediction Wrapper Testing"
output:
  html_notebook: default
  pdf_document: default
editor_options:
  chunk_output_type: inline
---

## General Prediction Wrapper

The test dataset we use to demonstrate this is the MASS Boston dataset for 
regression tasks, and the crabs dataset for classification tasks.
```{r}
library(MASS)
source("predictor.R")
source("interpret.R")
data <- MASS::Boston
set.seed(491)
test_ind <- sample(1:nrow(data), nrow(data)%/%5)
train_reg <- data[-test_ind,]
test_reg <- data[test_ind,]


data_class <- MASS::crabs
test_ind <- sample(1:nrow(data_class), nrow(data_class)%/%5)
train_class <- data_class[-test_ind,]
test_class <- data_class[test_ind,]

```


```{r}
# linear regression
linreg <- lm(crim ~., data=train_reg)
linreg_predictor <- Predictor$new(model = linreg, data = train_reg, y="crim",
                                  predict = predict, task = "regression")
actual <- predict(linreg, test_reg)
method <- predict.Predictor(linreg_predictor, test_reg) 
sum(actual != method) # all the same values

print(linreg_predictor)

linreginterpret <- Interpreter$new(predictor = linreg_predictor,
                                   feature = "indus")
plot.Interpreter(linreginterpret)
```


```{r}
# logistic regression
# Interpreter not yet implemented for classification (only for single variable probs)
logreg <- glm(sex ~., data=train_class, family=binomial(logit))
logreg_predictor <- Predictor$new(model=logreg, data=train_class, y="sex",
                                  type = "response", task = "classification")
actual <- predict(logreg, test_class, type = "response")
method <- predict.Predictor(logreg_predictor,test_class)
sum(actual!= method) # all the same values
print(logreg_predictor) 

```

```{r}
# decision tree for regression
library(rpart)
dectree <- rpart(crim ~., data=train_reg, method="anova")

dectree_predictor <- Predictor$new(model = dectree, data = train_reg, y="crim",
                                  predict = predict, task = "regression")
actual <- predict(dectree, test_reg)
method <- predict.Predictor(dectree_predictor,test_reg) 
sum(actual != method) # all the same values

print(dectree_predictor)

dectreeinterp <- Interpreter$new(predictor = dectree_predictor,
                                  feature = "dis")
plot.Interpreter(dectreeinterp)

```

```{r}
# decision tree for classification
dectree <- rpart(sex ~., data=train_class, method = "class")
dectree_predictor <- Predictor$new(model = dectree, data = train_class, y="sex",
                                  type = "prob", task = "classification")
actual <- predict(dectree, test_class, type= "prob")
method <- predict.Predictor(dectree_predictor,test_class)
sum(actual != method) # all the same values

head(method)

print(dectree_predictor)
```


```{r}
# Showcase class variable
dectree_predictor <- Predictor$new(model = dectree, data = train_class, y="sex",
                                  type = "prob", task = "classification", class = "F")
method <- predict.Predictor(dectree_predictor, test_class) 
head(method) # only shows female probabilites

dectreeinterp <- Interpreter$new(predictor = dectree_predictor,
                                  feature = "RW")
plot.Interpreter(dectreeinterp)
```


```{r}
# random forest
library(Rforestry)
forest <- forestry(x=train_reg[,-which(names(train_reg)=="crim")],
                   y=train_reg[,which(names(train_reg)=="crim")])
forest_predictor <- Predictor$new(model = forest, data=train_reg, y="crim",
                                  task = "regression")
actual <- predict(forest, test_reg[,-which(names(test_reg)=="crim")])
method <- predict.Predictor(forest_predictor,test_reg)

head(data.frame(actual,method)) # all the same values
forest_predictor$print()

forestinterp <- Interpreter$new(predictor = forest_predictor,
                                feature = "indus")
plot.Interpreter(forestinterp)

```


```{r}
#Xgboost
library(xgboost)
# feeding in its own function
predict_xgboost <- function(model, newdata){
  return(predict(model, xgb.DMatrix(data=as.matrix(newdata))))
}

xgb_model <- xgboost(data = xgb.DMatrix(label = train_reg$crim,
                                        data = as.matrix(train_reg[,-which(names(train_reg)=="crim")])),
                     verbose = 0, nrounds = 100)

xgb_predictor <- Predictor$new(model = xgb_model, data=train_reg, 
                               predict.func = predict_xgboost, y="crim",
                               task = "regression")

actual <- predict(xgb_model, xgb.DMatrix(data=as.matrix(
  test_reg[,-which(names(test_reg)=="crim")])))
method <- predict.Predictor(xgb_predictor,test_reg)

head(cbind(actual, method)) # same values

xgb_predictor$print()

xgbinterp <- Interpreter$new(predictor = xgb_predictor,
                             feature = "indus")
plot.Interpreter(xgbinterp)

```

